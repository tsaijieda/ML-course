{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define label mapping for classes\n",
    "label_map = {\n",
    "    \"tetragonal\": 0,\n",
    "    \"orthorhombic\": 1,\n",
    "    \"trigonal\": 2,\n",
    "    \"cubic\": 3,\n",
    "    \"triclinic\": 4,\n",
    "    \"monoclinic\": 5,\n",
    "    \"hexagonal\": 6\n",
    "}\n",
    "\n",
    "# Dataset Class\n",
    "class XRD_Dataset(Dataset):\n",
    "    def __init__(self, file_list, data_dir):\n",
    "        self.file_list = file_list\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name, label = self.file_list[idx]\n",
    "        file_name = file_name.replace('.cif', '_convolved.npz')\n",
    "        file_path = os.path.join(self.data_dir, file_name)\n",
    "        data = np.load(file_path)\n",
    "        x = np.stack((data['x_fine'], data['y_convolved']), axis=1).astype(np.float32)\n",
    "        label = label_map[label]\n",
    "        return x, label\n",
    "\n",
    "# Load the dataset\n",
    "csv_path = \"/ML-course/testdata/structure_info.csv\"\n",
    "data_dir = \"/ML-course/testdata/output_data\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Split into train and test sets\n",
    "train_files, test_files = train_test_split(df[['file_name', 'cell_structure']].values, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = XRD_Dataset(train_files, data_dir)\n",
    "test_dataset = XRD_Dataset(test_files, data_dir)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Vision Transformer Model\n",
    "from torchvision.models.vision_transformer import VisionTransformer\n",
    "\n",
    "class XRD_ViT(nn.Module):\n",
    "    def __init__(self, seq_length, num_classes):\n",
    "        super(XRD_ViT, self).__init__()\n",
    "        self.vit = VisionTransformer(\n",
    "            image_size=seq_length,        # Sequence length as the \"image size\"\n",
    "            patch_size=16,                # Patch size (adjust as needed)\n",
    "            num_classes=num_classes,      # Number of output classes\n",
    "            embed_dim=128,                # Embedding dimension\n",
    "            depth=6,                      # Number of transformer layers\n",
    "            num_heads=8,                  # Number of attention heads\n",
    "            mlp_dim=256,                  # Dimension of the MLP in ViT\n",
    "            dropout=0.1                   # Dropout rate\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vit(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "seq_length = 1000  # Replace with actual input sequence length\n",
    "num_classes = len(label_map)\n",
    "model = XRD_ViT(seq_length, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
