{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Essential Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training, Testing, Validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "數據加載完成：\n",
      "訓練集樣本數: 2100\n",
      "測試集樣本數: 2100\n",
      "驗證集樣本數: 245\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "label_map = {\n",
    "    \"tetragonal\": 0,\n",
    "    \"orthorhombic\": 1,\n",
    "    \"trigonal\": 2,\n",
    "    \"cubic\": 3,\n",
    "    \"triclinic\": 4,\n",
    "    \"monoclinic\": 5,\n",
    "    \"hexagonal\": 6\n",
    "}\n",
    "\n",
    "# 自定義 Dataset\n",
    "class XRD_Dataset(Dataset):\n",
    "    def __init__(self, file_list, data_dir):\n",
    "        self.file_list = file_list\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name, label = self.file_list[idx]\n",
    "        \n",
    "        # 將 .cif 檔名更改為 .npz\n",
    "        file_name = file_name.replace('.cif', '_convolved.npz')\n",
    "        \n",
    "        file_path = os.path.join(self.data_dir, file_name)\n",
    "        data = np.load(file_path)\n",
    "        x = np.stack((data['x_fine'], data['y_convolved']), axis=1).astype(np.float32)\n",
    "        # Map string label to integer index\n",
    "        label = label_map[label]\n",
    "        return x, label\n",
    "\n",
    "# 讀取 csv 文件\n",
    "csv_path = \"structure_info.csv\"  # 替換為實際 csv 文件路徑\n",
    "data_dir = \"D:/OLD_DATA/main/NTU/third_grade/ML_PHYS/project/output_data/output_data\"  # 包含 .npz 文件的目錄\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 分割數據集\n",
    "split_info = {\n",
    "    \"tetragonal\": (300, 300, 30),\n",
    "    \"orthorhombic\": (500, 500, 50),\n",
    "    \"trigonal\": (100, 100, 30),\n",
    "    \"cubic\": (500, 500, 50),\n",
    "    \"triclinic\": (100, 100, 30),\n",
    "    \"monoclinic\": (500, 500, 50),\n",
    "    \"hexagonal\": (100, 100, 5)\n",
    "}\n",
    "\n",
    "train_list, test_list, val_list = [], [], []\n",
    "\n",
    "for label, (train_size, test_size, val_size) in split_info.items():\n",
    "    files = df[df['cell_structure'] == label][['filename', 'cell_structure']].values.tolist()\n",
    "    \n",
    "    # 分割成訓練、測試、驗證集\n",
    "    train_files, temp_files = train_test_split(files, train_size=train_size, random_state=42)\n",
    "    test_files, temp_files = train_test_split(temp_files, train_size=test_size, random_state=42)\n",
    "    val_files, temp_files = train_test_split(temp_files, train_size=val_size, random_state=42)\n",
    "    \n",
    "    train_list.extend(train_files)\n",
    "    test_list.extend(test_files)\n",
    "    val_list.extend(val_files)\n",
    "\n",
    "# 創建 DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = XRD_Dataset(train_list, data_dir)\n",
    "test_dataset = XRD_Dataset(test_list, data_dir)\n",
    "val_dataset = XRD_Dataset(val_list, data_dir)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"數據加載完成：\")\n",
    "print(f\"訓練集樣本數: {len(train_dataset)}\")\n",
    "print(f\"測試集樣本數: {len(test_dataset)}\")\n",
    "print(f\"驗證集樣本數: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define CNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class XRD_CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(XRD_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1062, 256)  # 1062 是 8500 經過 3 次 MaxPooling1d(2) 後的大小\n",
    "        self.fc2 = nn.Linear(256, num_classes)  # `num_classes` 是 cell_structure 的種類數\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # 最後一層輸出 logits\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XRD_CNN(\n",
      "  (conv1): Conv1d(2, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=135936, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 定義類別數量（如晶系數量）\n",
    "num_classes = 7\n",
    "\n",
    "# 初始化模型\n",
    "model = XRD_CNN(num_classes=num_classes)\n",
    "print(model)\n",
    "\n",
    "# 定義損失函數與優化器\n",
    "criterion = nn.CrossEntropyLoss()  # 用於分類問題\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 訓練範例\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.permute(0, 2, 1)  # (batch_size, 8500, 2) -> (batch_size, 2, 8500)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            print(f\"Loss = {loss.item()}\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 1.8737156391143799\n",
      "Loss = 86.90399169921875\n",
      "Loss = 85.5404052734375\n",
      "Loss = 80.49240112304688\n",
      "Loss = 66.21749877929688\n",
      "Loss = 41.86954116821289\n",
      "Loss = 23.678503036499023\n",
      "Loss = 9.794734001159668\n",
      "Loss = 4.6292643547058105\n",
      "Loss = 2.2348783016204834\n",
      "Loss = 1.5911495685577393\n",
      "Loss = 2.0745062828063965\n",
      "Loss = 1.8824174404144287\n",
      "Loss = 3.565629243850708\n",
      "Loss = 2.4234955310821533\n",
      "Loss = 2.167215585708618\n",
      "Loss = 2.1616640090942383\n",
      "Loss = 1.978990077972412\n",
      "Loss = 1.9053982496261597\n",
      "Loss = 2.0071120262145996\n",
      "Loss = 1.984639286994934\n",
      "Loss = 1.8313980102539062\n",
      "Loss = 1.9406851530075073\n",
      "Loss = 1.696266770362854\n",
      "Loss = 1.7061768770217896\n",
      "Loss = 1.7264364957809448\n",
      "Loss = 1.9489901065826416\n",
      "Loss = 1.7845884561538696\n",
      "Loss = 1.773022174835205\n",
      "Loss = 1.7658648490905762\n",
      "Loss = 1.8151524066925049\n",
      "Loss = 1.6436835527420044\n",
      "Loss = 1.8170974254608154\n",
      "Loss = 1.7820680141448975\n",
      "Loss = 1.6926569938659668\n",
      "Loss = 1.5802555084228516\n",
      "Loss = 1.6820626258850098\n",
      "Loss = 1.5848362445831299\n",
      "Loss = 1.9022822380065918\n",
      "Loss = 1.6553410291671753\n",
      "Loss = 1.9308346509933472\n",
      "Loss = 1.7309529781341553\n",
      "Loss = 1.5975730419158936\n",
      "Loss = 1.8647195100784302\n",
      "Loss = 1.7900855541229248\n",
      "Loss = 1.8076679706573486\n",
      "Loss = 1.9332481622695923\n",
      "Loss = 1.8018743991851807\n",
      "Loss = 1.766165852546692\n",
      "Loss = 1.8151313066482544\n",
      "Loss = 1.8718396425247192\n",
      "Loss = 1.6893421411514282\n",
      "Loss = 1.9206032752990723\n",
      "Loss = 1.6569135189056396\n",
      "Loss = 1.8423855304718018\n",
      "Loss = 1.7938435077667236\n",
      "Loss = 1.6935570240020752\n",
      "Loss = 1.7655082941055298\n",
      "Loss = 1.7617770433425903\n",
      "Loss = 1.7843120098114014\n",
      "Loss = 1.6785428524017334\n",
      "Loss = 1.6326935291290283\n",
      "Loss = 1.8800967931747437\n",
      "Loss = 1.8078874349594116\n",
      "Loss = 1.6556708812713623\n",
      "Loss = 2.021580219268799\n",
      "Epoch 1/20, Loss: 7.6788\n",
      "Loss = 1.7001125812530518\n",
      "Loss = 1.6972026824951172\n",
      "Loss = 1.7339599132537842\n",
      "Loss = 1.6299725770950317\n",
      "Loss = 1.7716728448867798\n",
      "Loss = 1.680940866470337\n",
      "Loss = 1.7523460388183594\n",
      "Loss = 1.7855727672576904\n",
      "Loss = 1.7442991733551025\n",
      "Loss = 1.6704281568527222\n",
      "Loss = 1.7351820468902588\n",
      "Loss = 1.64993155002594\n",
      "Loss = 1.9077352285385132\n",
      "Loss = 1.867923378944397\n",
      "Loss = 1.7954270839691162\n",
      "Loss = 1.752488374710083\n",
      "Loss = 1.8395297527313232\n",
      "Loss = 1.7195240259170532\n",
      "Loss = 1.695495367050171\n",
      "Loss = 2.0197203159332275\n",
      "Loss = 1.6899977922439575\n",
      "Loss = 1.5914727449417114\n",
      "Loss = 1.5074107646942139\n",
      "Loss = 1.5313735008239746\n",
      "Loss = 1.675917387008667\n",
      "Loss = 2.186185359954834\n",
      "Loss = 1.8262598514556885\n",
      "Loss = 1.9723924398422241\n",
      "Loss = 1.8229615688323975\n",
      "Loss = 1.906258463859558\n",
      "Loss = 1.914265751838684\n",
      "Loss = 1.9084680080413818\n",
      "Loss = 1.9033125638961792\n",
      "Loss = 1.8078017234802246\n",
      "Loss = 1.7469699382781982\n",
      "Loss = 1.6218135356903076\n",
      "Loss = 1.861402153968811\n",
      "Loss = 1.8589922189712524\n",
      "Loss = 1.8834753036499023\n",
      "Loss = 1.8059767484664917\n",
      "Loss = 1.66347074508667\n",
      "Loss = 1.909114956855774\n",
      "Loss = 1.7373944520950317\n",
      "Loss = 1.6722469329833984\n",
      "Loss = 1.853500485420227\n",
      "Loss = 1.7399601936340332\n",
      "Loss = 1.6520265340805054\n",
      "Loss = 1.83914315700531\n",
      "Loss = 1.6396907567977905\n",
      "Loss = 1.6763135194778442\n",
      "Loss = 1.7776049375534058\n",
      "Loss = 1.64555823802948\n",
      "Loss = 1.8638135194778442\n",
      "Loss = 1.8557515144348145\n",
      "Loss = 1.8157682418823242\n",
      "Loss = 1.6952887773513794\n",
      "Loss = 1.5644745826721191\n",
      "Loss = 1.6722028255462646\n",
      "Loss = 1.7945483922958374\n",
      "Loss = 1.9343855381011963\n",
      "Loss = 1.7516429424285889\n",
      "Loss = 1.8424808979034424\n",
      "Loss = 1.7439780235290527\n",
      "Loss = 1.7866156101226807\n",
      "Loss = 1.7744218111038208\n",
      "Loss = 1.6301597356796265\n",
      "Epoch 2/20, Loss: 1.7682\n",
      "Loss = 1.7044895887374878\n",
      "Loss = 1.88144850730896\n",
      "Loss = 1.5475085973739624\n",
      "Loss = 1.642427921295166\n",
      "Loss = 1.8462265729904175\n",
      "Loss = 1.8327618837356567\n",
      "Loss = 1.705479383468628\n",
      "Loss = 1.7586981058120728\n",
      "Loss = 1.6369901895523071\n",
      "Loss = 1.7843573093414307\n",
      "Loss = 1.8539354801177979\n",
      "Loss = 1.800072431564331\n",
      "Loss = 1.685052514076233\n",
      "Loss = 1.656448483467102\n",
      "Loss = 1.7295334339141846\n",
      "Loss = 1.7098145484924316\n",
      "Loss = 1.838443398475647\n",
      "Loss = 1.9000791311264038\n",
      "Loss = 1.64751136302948\n",
      "Loss = 1.563810110092163\n",
      "Loss = 1.7407960891723633\n",
      "Loss = 1.9334959983825684\n",
      "Loss = 1.7950475215911865\n",
      "Loss = 1.7333159446716309\n",
      "Loss = 1.6948267221450806\n",
      "Loss = 1.7595491409301758\n",
      "Loss = 1.803025722503662\n",
      "Loss = 1.7096712589263916\n",
      "Loss = 1.8407189846038818\n",
      "Loss = 1.6759330034255981\n",
      "Loss = 1.828309416770935\n",
      "Loss = 1.7968113422393799\n",
      "Loss = 1.5456385612487793\n",
      "Loss = 1.7069475650787354\n",
      "Loss = 1.703980565071106\n",
      "Loss = 1.8653788566589355\n",
      "Loss = 1.8284190893173218\n",
      "Loss = 1.7404351234436035\n",
      "Loss = 1.6372387409210205\n",
      "Loss = 1.800609827041626\n",
      "Loss = 1.7466716766357422\n",
      "Loss = 1.7169302701950073\n",
      "Loss = 1.8285197019577026\n",
      "Loss = 1.764488935470581\n",
      "Loss = 1.6863713264465332\n",
      "Loss = 1.7298887968063354\n",
      "Loss = 1.8748716115951538\n",
      "Loss = 1.6422499418258667\n",
      "Loss = 1.8854014873504639\n",
      "Loss = 1.7999687194824219\n",
      "Loss = 1.8011515140533447\n",
      "Loss = 1.8166636228561401\n",
      "Loss = 1.7728157043457031\n",
      "Loss = 1.721895694732666\n",
      "Loss = 1.8075724840164185\n",
      "Loss = 1.8972070217132568\n",
      "Loss = 1.65015709400177\n",
      "Loss = 1.6514880657196045\n",
      "Loss = 1.7983616590499878\n",
      "Loss = 1.887683391571045\n",
      "Loss = 1.94498610496521\n",
      "Loss = 1.8044780492782593\n",
      "Loss = 1.7298930883407593\n",
      "Loss = 1.6417516469955444\n",
      "Loss = 1.827026128768921\n",
      "Loss = 1.5489866733551025\n",
      "Epoch 3/20, Loss: 1.7552\n",
      "Loss = 1.802274465560913\n",
      "Loss = 1.8419297933578491\n",
      "Loss = 1.7775993347167969\n",
      "Loss = 1.902968168258667\n",
      "Loss = 1.7576416730880737\n",
      "Loss = 1.766783356666565\n",
      "Loss = 1.810922384262085\n",
      "Loss = 1.8682781457901\n",
      "Loss = 1.8983607292175293\n",
      "Loss = 1.8053237199783325\n",
      "Loss = 1.7809779644012451\n",
      "Loss = 1.679136872291565\n",
      "Loss = 1.764418601989746\n",
      "Loss = 1.7382087707519531\n",
      "Loss = 1.685021996498108\n",
      "Loss = 1.7854764461517334\n",
      "Loss = 1.4616762399673462\n",
      "Loss = 1.8047312498092651\n",
      "Loss = 1.578052043914795\n",
      "Loss = 2.298344135284424\n",
      "Loss = 1.5452957153320312\n",
      "Loss = 1.8277033567428589\n",
      "Loss = 1.7880326509475708\n",
      "Loss = 1.7869935035705566\n",
      "Loss = 1.8341851234436035\n",
      "Loss = 1.8654841184616089\n",
      "Loss = 1.802403450012207\n",
      "Loss = 1.8017616271972656\n",
      "Loss = 1.7915785312652588\n",
      "Loss = 1.730485439300537\n",
      "Loss = 1.6245614290237427\n",
      "Loss = 1.7719340324401855\n",
      "Loss = 1.8219279050827026\n",
      "Loss = 1.8407098054885864\n",
      "Loss = 1.5277595520019531\n",
      "Loss = 1.6456443071365356\n",
      "Loss = 1.9177048206329346\n",
      "Loss = 1.839186668395996\n",
      "Loss = 1.6526321172714233\n",
      "Loss = 1.9814527034759521\n",
      "Loss = 1.7936837673187256\n",
      "Loss = 1.6738896369934082\n",
      "Loss = 1.821220874786377\n",
      "Loss = 1.8203098773956299\n",
      "Loss = 1.7746814489364624\n",
      "Loss = 1.8083882331848145\n",
      "Loss = 1.7311723232269287\n",
      "Loss = 1.818994402885437\n",
      "Loss = 1.7584562301635742\n",
      "Loss = 1.72457754611969\n",
      "Loss = 1.5806454420089722\n",
      "Loss = 1.6985552310943604\n",
      "Loss = 1.8993548154830933\n",
      "Loss = 2.0721142292022705\n",
      "Loss = 1.6961040496826172\n",
      "Loss = 1.6018874645233154\n",
      "Loss = 1.6774277687072754\n",
      "Loss = 1.7444988489151\n",
      "Loss = 1.7753833532333374\n",
      "Loss = 1.7083548307418823\n",
      "Loss = 1.7004368305206299\n",
      "Loss = 1.7288490533828735\n",
      "Loss = 1.8712499141693115\n",
      "Loss = 1.6099565029144287\n",
      "Loss = 1.7008575201034546\n",
      "Loss = 1.9451792240142822\n",
      "Epoch 4/20, Loss: 1.7718\n",
      "Loss = 1.8448597192764282\n",
      "Loss = 1.97810697555542\n",
      "Loss = 1.7529617547988892\n",
      "Loss = 1.8243495225906372\n",
      "Loss = 1.8649853467941284\n",
      "Loss = 1.8715344667434692\n",
      "Loss = 1.8173118829727173\n",
      "Loss = 1.7276194095611572\n",
      "Loss = 1.7596485614776611\n",
      "Loss = 1.7247521877288818\n",
      "Loss = 1.6634784936904907\n",
      "Loss = 1.5998374223709106\n",
      "Loss = 1.9200987815856934\n",
      "Loss = 1.7009791135787964\n",
      "Loss = 1.8794926404953003\n",
      "Loss = 1.961268663406372\n",
      "Loss = 1.7254959344863892\n",
      "Loss = 1.8037664890289307\n",
      "Loss = 1.7650635242462158\n",
      "Loss = 1.7605077028274536\n",
      "Loss = 1.8648571968078613\n",
      "Loss = 1.628625750541687\n",
      "Loss = 1.8287550210952759\n",
      "Loss = 1.6595045328140259\n",
      "Loss = 1.7036285400390625\n",
      "Loss = 1.8780063390731812\n",
      "Loss = 1.8075212240219116\n",
      "Loss = 1.8894814252853394\n",
      "Loss = 1.839779019355774\n",
      "Loss = 1.7760918140411377\n",
      "Loss = 1.8442200422286987\n",
      "Loss = 1.7782559394836426\n",
      "Loss = 1.8037983179092407\n",
      "Loss = 1.710775375366211\n",
      "Loss = 1.770199179649353\n",
      "Loss = 1.6334680318832397\n",
      "Loss = 1.7412004470825195\n",
      "Loss = 1.5084388256072998\n",
      "Loss = 1.667581558227539\n",
      "Loss = 1.764860987663269\n",
      "Loss = 2.1483519077301025\n",
      "Loss = 1.9067398309707642\n",
      "Loss = 1.599570870399475\n",
      "Loss = 1.5773295164108276\n",
      "Loss = 1.8007441759109497\n",
      "Loss = 1.6571762561798096\n",
      "Loss = 1.7508755922317505\n",
      "Loss = 1.9602372646331787\n",
      "Loss = 1.8713645935058594\n",
      "Loss = 1.7311146259307861\n",
      "Loss = 1.9417743682861328\n",
      "Loss = 1.739689588546753\n",
      "Loss = 1.844948172569275\n",
      "Loss = 1.8212751150131226\n",
      "Loss = 1.654349684715271\n",
      "Loss = 1.7660447359085083\n",
      "Loss = 1.8783190250396729\n",
      "Loss = 1.6516127586364746\n",
      "Loss = 1.7992463111877441\n",
      "Loss = 1.7250686883926392\n",
      "Loss = 1.6811152696609497\n",
      "Loss = 1.78191077709198\n",
      "Loss = 1.695298194885254\n",
      "Loss = 1.690374493598938\n",
      "Loss = 1.7344188690185547\n",
      "Loss = 1.502034068107605\n",
      "Epoch 5/20, Loss: 1.7721\n",
      "Loss = 1.7953747510910034\n",
      "Loss = 1.8836312294006348\n",
      "Loss = 1.5477242469787598\n",
      "Loss = 1.6212897300720215\n",
      "Loss = 1.955102801322937\n",
      "Loss = 1.667924404144287\n",
      "Loss = 1.7585527896881104\n",
      "Loss = 1.7389941215515137\n",
      "Loss = 1.9053720235824585\n",
      "Loss = 1.680845856666565\n",
      "Loss = 1.777078628540039\n",
      "Loss = 1.6588754653930664\n",
      "Loss = 1.8944495916366577\n",
      "Loss = 1.7103127241134644\n",
      "Loss = 1.8329228162765503\n",
      "Loss = 1.722230076789856\n",
      "Loss = 1.7023073434829712\n",
      "Loss = 1.8718721866607666\n",
      "Loss = 1.6191397905349731\n",
      "Loss = 1.7322036027908325\n",
      "Loss = 1.7584131956100464\n",
      "Loss = 1.7708539962768555\n",
      "Loss = 2.133819818496704\n",
      "Loss = 1.8320811986923218\n",
      "Loss = 1.6372331380844116\n",
      "Loss = 1.8483374118804932\n",
      "Loss = 1.780545949935913\n",
      "Loss = 1.600511074066162\n",
      "Loss = 1.8402650356292725\n",
      "Loss = 1.7888579368591309\n",
      "Loss = 1.6647642850875854\n",
      "Loss = 1.7602899074554443\n",
      "Loss = 1.7886979579925537\n",
      "Loss = 1.9089322090148926\n",
      "Loss = 1.7861601114273071\n",
      "Loss = 1.7332873344421387\n",
      "Loss = 1.6729285717010498\n",
      "Loss = 1.5797700881958008\n",
      "Loss = 1.7935713529586792\n",
      "Loss = 1.6983447074890137\n",
      "Loss = 1.6204719543457031\n",
      "Loss = 1.734480381011963\n",
      "Loss = 1.6691241264343262\n",
      "Loss = 1.5889379978179932\n",
      "Loss = 1.8336129188537598\n",
      "Loss = 1.641160249710083\n",
      "Loss = 2.04778790473938\n",
      "Loss = 1.7690662145614624\n",
      "Loss = 1.7551482915878296\n",
      "Loss = 1.7783138751983643\n",
      "Loss = 1.6903047561645508\n",
      "Loss = 1.6948460340499878\n",
      "Loss = 1.8027563095092773\n",
      "Loss = 2.0474588871002197\n",
      "Loss = 1.7466847896575928\n",
      "Loss = 1.783154010772705\n",
      "Loss = 1.7110837697982788\n",
      "Loss = 1.7495163679122925\n",
      "Loss = 1.6568909883499146\n",
      "Loss = 1.8261488676071167\n",
      "Loss = 1.729049801826477\n",
      "Loss = 1.7512099742889404\n",
      "Loss = 1.762934923171997\n",
      "Loss = 1.8540393114089966\n",
      "Loss = 1.8540396690368652\n",
      "Loss = 1.683423638343811\n",
      "Epoch 6/20, Loss: 1.7611\n",
      "Loss = 1.8753968477249146\n",
      "Loss = 1.6890839338302612\n",
      "Loss = 1.7346601486206055\n",
      "Loss = 1.8787431716918945\n",
      "Loss = 1.6425938606262207\n",
      "Loss = 1.7946656942367554\n",
      "Loss = 1.6843061447143555\n",
      "Loss = 1.5955426692962646\n",
      "Loss = 1.890454888343811\n",
      "Loss = 1.8798589706420898\n",
      "Loss = 1.8098751306533813\n",
      "Loss = 1.5791997909545898\n",
      "Loss = 1.7153880596160889\n",
      "Loss = 1.8376163244247437\n",
      "Loss = 1.6736501455307007\n",
      "Loss = 1.9158740043640137\n",
      "Loss = 1.706621527671814\n",
      "Loss = 1.7067694664001465\n",
      "Loss = 1.7910914421081543\n",
      "Loss = 1.604466438293457\n",
      "Loss = 1.6819559335708618\n",
      "Loss = 2.121654987335205\n",
      "Loss = 1.7258576154708862\n",
      "Loss = 1.7924867868423462\n",
      "Loss = 1.8651841878890991\n",
      "Loss = 1.7562124729156494\n",
      "Loss = 1.7700656652450562\n",
      "Loss = 1.6880666017532349\n",
      "Loss = 1.7285795211791992\n",
      "Loss = 1.7546268701553345\n",
      "Loss = 1.7978845834732056\n",
      "Loss = 1.8058558702468872\n",
      "Loss = 1.8451216220855713\n",
      "Loss = 1.646718144416809\n",
      "Loss = 1.7910866737365723\n",
      "Loss = 1.9743130207061768\n",
      "Loss = 1.7385013103485107\n",
      "Loss = 1.7367817163467407\n",
      "Loss = 1.7379076480865479\n",
      "Loss = 1.8356499671936035\n",
      "Loss = 1.7929985523223877\n",
      "Loss = 1.8467413187026978\n",
      "Loss = 1.8171731233596802\n",
      "Loss = 1.732990026473999\n",
      "Loss = 1.7241716384887695\n",
      "Loss = 1.6235339641571045\n",
      "Loss = 1.7122809886932373\n",
      "Loss = 1.796242117881775\n",
      "Loss = 1.7663017511367798\n",
      "Loss = 2.1668198108673096\n",
      "Loss = 1.8790154457092285\n",
      "Loss = 1.5936609506607056\n",
      "Loss = 1.7135009765625\n",
      "Loss = 1.9182825088500977\n",
      "Loss = 1.7723441123962402\n",
      "Loss = 1.7207727432250977\n",
      "Loss = 1.690768837928772\n",
      "Loss = 1.7089009284973145\n",
      "Loss = 1.6895555257797241\n",
      "Loss = 1.612938404083252\n",
      "Loss = 1.6203534603118896\n",
      "Loss = 1.9140039682388306\n",
      "Loss = 1.704787254333496\n",
      "Loss = 1.953845739364624\n",
      "Loss = 1.7236725091934204\n",
      "Loss = 1.7904924154281616\n",
      "Epoch 7/20, Loss: 1.7695\n",
      "Loss = 1.7266957759857178\n",
      "Loss = 1.7548624277114868\n",
      "Loss = 1.8338403701782227\n",
      "Loss = 1.8220694065093994\n",
      "Loss = 1.7578516006469727\n",
      "Loss = 1.817652702331543\n",
      "Loss = 1.8185405731201172\n",
      "Loss = 1.7913333177566528\n",
      "Loss = 1.9127686023712158\n",
      "Loss = 1.6842485666275024\n",
      "Loss = 1.7849931716918945\n",
      "Loss = 1.7551625967025757\n",
      "Loss = 1.6724334955215454\n",
      "Loss = 1.9557678699493408\n",
      "Loss = 1.8690166473388672\n",
      "Loss = 1.9209709167480469\n",
      "Loss = 1.731298565864563\n",
      "Loss = 1.7769198417663574\n",
      "Loss = 1.9374397993087769\n",
      "Loss = 1.904513955116272\n",
      "Loss = 1.7240043878555298\n",
      "Loss = 1.8449039459228516\n",
      "Loss = 1.7723933458328247\n",
      "Loss = 1.7637100219726562\n",
      "Loss = 1.7820667028427124\n",
      "Loss = 1.7761448621749878\n",
      "Loss = 1.6906846761703491\n",
      "Loss = 1.723677635192871\n",
      "Loss = 1.770437240600586\n",
      "Loss = 2.035667657852173\n",
      "Loss = 2.0224199295043945\n",
      "Loss = 1.6390594244003296\n",
      "Loss = 1.7643769979476929\n",
      "Loss = 1.664953589439392\n",
      "Loss = 1.7463634014129639\n",
      "Loss = 1.7498016357421875\n",
      "Loss = 1.7558871507644653\n",
      "Loss = 1.556249737739563\n",
      "Loss = 1.8194490671157837\n",
      "Loss = 1.635793924331665\n",
      "Loss = 1.8236116170883179\n",
      "Loss = 1.9234942197799683\n",
      "Loss = 1.8200674057006836\n",
      "Loss = 1.9221473932266235\n",
      "Loss = 1.59797203540802\n",
      "Loss = 1.7461419105529785\n",
      "Loss = 1.7436041831970215\n",
      "Loss = 1.731384038925171\n",
      "Loss = 1.769412636756897\n",
      "Loss = 1.8691494464874268\n",
      "Loss = 1.7820427417755127\n",
      "Loss = 1.8758162260055542\n",
      "Loss = 1.780431866645813\n",
      "Loss = 1.543757677078247\n",
      "Loss = 1.7371351718902588\n",
      "Loss = 1.702713966369629\n",
      "Loss = 1.7201178073883057\n",
      "Loss = 1.5837891101837158\n",
      "Loss = 1.6849762201309204\n",
      "Loss = 1.5638256072998047\n",
      "Loss = 1.675978183746338\n",
      "Loss = 1.8640693426132202\n",
      "Loss = 1.6945384740829468\n",
      "Loss = 1.7316102981567383\n",
      "Loss = 1.8420432806015015\n",
      "Loss = 1.7968339920043945\n",
      "Epoch 8/20, Loss: 1.7726\n",
      "Loss = 1.596652865409851\n",
      "Loss = 1.744403600692749\n",
      "Loss = 1.7764017581939697\n",
      "Loss = 1.9092228412628174\n",
      "Loss = 1.8145990371704102\n",
      "Loss = 1.7629212141036987\n",
      "Loss = 1.6720492839813232\n",
      "Loss = 1.716903567314148\n",
      "Loss = 1.667424201965332\n",
      "Loss = 1.8334611654281616\n",
      "Loss = 1.7402821779251099\n",
      "Loss = 1.885430932044983\n",
      "Loss = 1.8198398351669312\n",
      "Loss = 1.7807483673095703\n",
      "Loss = 1.7822484970092773\n",
      "Loss = 1.6384409666061401\n",
      "Loss = 1.816213607788086\n",
      "Loss = 1.9121592044830322\n",
      "Loss = 1.7736635208129883\n",
      "Loss = 1.7928495407104492\n",
      "Loss = 1.6885451078414917\n",
      "Loss = 1.707292079925537\n",
      "Loss = 1.7846777439117432\n",
      "Loss = 1.6064714193344116\n",
      "Loss = 1.6934963464736938\n",
      "Loss = 1.809389591217041\n",
      "Loss = 1.7113279104232788\n",
      "Loss = 2.0325729846954346\n",
      "Loss = 1.8632303476333618\n",
      "Loss = 1.6775838136672974\n",
      "Loss = 1.788107991218567\n",
      "Loss = 1.846317172050476\n",
      "Loss = 1.7504289150238037\n",
      "Loss = 1.6908453702926636\n",
      "Loss = 1.7387446165084839\n",
      "Loss = 1.7586655616760254\n",
      "Loss = 1.6866031885147095\n",
      "Loss = 1.7658874988555908\n",
      "Loss = 1.6441113948822021\n",
      "Loss = 1.8512217998504639\n",
      "Loss = 1.777569055557251\n",
      "Loss = 1.6978241205215454\n",
      "Loss = 1.819790005683899\n",
      "Loss = 1.7203501462936401\n",
      "Loss = 1.7703375816345215\n",
      "Loss = 1.719906210899353\n",
      "Loss = 1.8791474103927612\n",
      "Loss = 1.7751541137695312\n",
      "Loss = 1.7039644718170166\n",
      "Loss = 1.7949633598327637\n",
      "Loss = 1.696797490119934\n",
      "Loss = 1.6724950075149536\n",
      "Loss = 1.8002629280090332\n",
      "Loss = 1.8410884141921997\n",
      "Loss = 1.677083969116211\n",
      "Loss = 1.813644289970398\n",
      "Loss = 1.9554963111877441\n",
      "Loss = 1.636164903640747\n",
      "Loss = 1.737215518951416\n",
      "Loss = 1.668660044670105\n",
      "Loss = 1.7459640502929688\n",
      "Loss = 1.7186812162399292\n",
      "Loss = 1.7073725461959839\n",
      "Loss = 1.8748780488967896\n",
      "Loss = 1.5432432889938354\n",
      "Loss = 1.5598653554916382\n",
      "Epoch 9/20, Loss: 1.7551\n",
      "Loss = 1.5011944770812988\n",
      "Loss = 1.7672353982925415\n",
      "Loss = 1.778850793838501\n",
      "Loss = 1.8267711400985718\n",
      "Loss = 1.8216160535812378\n",
      "Loss = 1.644517421722412\n",
      "Loss = 1.73291015625\n",
      "Loss = 1.5725653171539307\n",
      "Loss = 1.8022011518478394\n",
      "Loss = 1.6735717058181763\n",
      "Loss = 1.8189038038253784\n",
      "Loss = 1.7262710332870483\n",
      "Loss = 1.740148901939392\n",
      "Loss = 1.7578953504562378\n",
      "Loss = 1.6918842792510986\n",
      "Loss = 1.7320119142532349\n",
      "Loss = 1.8280993700027466\n",
      "Loss = 1.7524161338806152\n",
      "Loss = 1.8125593662261963\n",
      "Loss = 1.6729577779769897\n",
      "Loss = 1.7991390228271484\n",
      "Loss = 1.834302544593811\n",
      "Loss = 1.7543628215789795\n",
      "Loss = 1.8090437650680542\n",
      "Loss = 1.9040796756744385\n",
      "Loss = 1.7178750038146973\n",
      "Loss = 1.725758671760559\n",
      "Loss = 1.7641801834106445\n",
      "Loss = 1.858328104019165\n",
      "Loss = 1.7285915613174438\n",
      "Loss = 1.8810328245162964\n",
      "Loss = 1.7933282852172852\n",
      "Loss = 1.9295148849487305\n",
      "Loss = 1.7996013164520264\n",
      "Loss = 1.663193941116333\n",
      "Loss = 1.993327021598816\n",
      "Loss = 1.8023165464401245\n",
      "Loss = 1.6132181882858276\n",
      "Loss = 1.9269165992736816\n",
      "Loss = 1.7444393634796143\n",
      "Loss = 1.8279249668121338\n",
      "Loss = 1.6695417165756226\n",
      "Loss = 1.7059131860733032\n",
      "Loss = 1.67724609375\n",
      "Loss = 1.8091251850128174\n",
      "Loss = 2.00140118598938\n",
      "Loss = 1.6160560846328735\n",
      "Loss = 1.767754316329956\n",
      "Loss = 1.77107572555542\n",
      "Loss = 1.6532214879989624\n",
      "Loss = 1.705704689025879\n",
      "Loss = 1.798679232597351\n",
      "Loss = 1.6169623136520386\n",
      "Loss = 1.7465635538101196\n",
      "Loss = 1.8778637647628784\n",
      "Loss = 1.7451940774917603\n",
      "Loss = 1.632951021194458\n",
      "Loss = 1.893333077430725\n",
      "Loss = 1.648126482963562\n",
      "Loss = 1.602325439453125\n",
      "Loss = 1.9335353374481201\n",
      "Loss = 1.6820757389068604\n",
      "Loss = 1.6749101877212524\n",
      "Loss = 1.663218379020691\n",
      "Loss = 1.842664122581482\n",
      "Loss = 1.888218879699707\n",
      "Epoch 10/20, Loss: 1.7598\n",
      "Loss = 1.8237860202789307\n",
      "Loss = 1.805113673210144\n",
      "Loss = 1.8595298528671265\n",
      "Loss = 1.8097693920135498\n",
      "Loss = 1.7796491384506226\n",
      "Loss = 1.7373923063278198\n",
      "Loss = 1.61042320728302\n",
      "Loss = 1.820152759552002\n",
      "Loss = 1.5432469844818115\n",
      "Loss = 1.7675237655639648\n",
      "Loss = 1.9098104238510132\n",
      "Loss = 1.4975850582122803\n",
      "Loss = 1.9546200037002563\n",
      "Loss = 1.8329771757125854\n",
      "Loss = 1.864054560661316\n",
      "Loss = 1.7359784841537476\n",
      "Loss = 1.733054757118225\n",
      "Loss = 1.715380072593689\n",
      "Loss = 1.7712637186050415\n",
      "Loss = 1.8427542448043823\n",
      "Loss = 1.7480758428573608\n",
      "Loss = 1.6688590049743652\n",
      "Loss = 1.696768045425415\n",
      "Loss = 1.8328582048416138\n",
      "Loss = 1.827787160873413\n",
      "Loss = 1.755271077156067\n",
      "Loss = 1.6485706567764282\n",
      "Loss = 1.5657737255096436\n",
      "Loss = 1.880493402481079\n",
      "Loss = 1.5581834316253662\n",
      "Loss = 1.671921730041504\n",
      "Loss = 2.0985636711120605\n",
      "Loss = 1.9160815477371216\n",
      "Loss = 1.8141896724700928\n",
      "Loss = 1.7148048877716064\n",
      "Loss = 1.7218068838119507\n",
      "Loss = 1.7211880683898926\n",
      "Loss = 1.7330222129821777\n",
      "Loss = 1.8829045295715332\n",
      "Loss = 1.79559326171875\n",
      "Loss = 1.780853271484375\n",
      "Loss = 1.7438485622406006\n",
      "Loss = 1.775526523590088\n",
      "Loss = 1.7014862298965454\n",
      "Loss = 1.7572258710861206\n",
      "Loss = 1.741523265838623\n",
      "Loss = 1.817931056022644\n",
      "Loss = 1.7493681907653809\n",
      "Loss = 2.0045535564422607\n",
      "Loss = 1.7755926847457886\n",
      "Loss = 1.722926139831543\n",
      "Loss = 1.892860770225525\n",
      "Loss = 1.8171660900115967\n",
      "Loss = 1.7128344774246216\n",
      "Loss = 1.657537579536438\n",
      "Loss = 1.7315043210983276\n",
      "Loss = 1.820068597793579\n",
      "Loss = 1.7611844539642334\n",
      "Loss = 1.8041160106658936\n",
      "Loss = 1.7738364934921265\n",
      "Loss = 1.8239365816116333\n",
      "Loss = 1.715561866760254\n",
      "Loss = 1.7403392791748047\n",
      "Loss = 1.737560510635376\n",
      "Loss = 1.7670525312423706\n",
      "Loss = 1.6863911151885986\n",
      "Epoch 11/20, Loss: 1.7679\n",
      "Loss = 1.8007807731628418\n",
      "Loss = 1.7378793954849243\n",
      "Loss = 1.7428263425827026\n",
      "Loss = 1.9108294248580933\n",
      "Loss = 1.7740890979766846\n",
      "Loss = 1.691384196281433\n",
      "Loss = 1.8504258394241333\n",
      "Loss = 1.7683426141738892\n",
      "Loss = 1.7668185234069824\n",
      "Loss = 1.7471054792404175\n",
      "Loss = 1.8252476453781128\n",
      "Loss = 1.8802287578582764\n",
      "Loss = 1.7389394044876099\n",
      "Loss = 1.808364987373352\n",
      "Loss = 1.753183364868164\n",
      "Loss = 1.8992621898651123\n",
      "Loss = 1.8965706825256348\n",
      "Loss = 1.7000881433486938\n",
      "Loss = 1.8088716268539429\n",
      "Loss = 1.750639796257019\n",
      "Loss = 1.7898722887039185\n",
      "Loss = 1.8525639772415161\n",
      "Loss = 1.9119782447814941\n",
      "Loss = 1.6514557600021362\n",
      "Loss = 1.7386651039123535\n",
      "Loss = 1.519744634628296\n",
      "Loss = 1.8601700067520142\n",
      "Loss = 1.7962229251861572\n",
      "Loss = 1.7272356748580933\n",
      "Loss = 1.8612442016601562\n",
      "Loss = 1.756182312965393\n",
      "Loss = 1.5836416482925415\n",
      "Loss = 1.738930344581604\n",
      "Loss = 1.6772396564483643\n",
      "Loss = 1.4860858917236328\n",
      "Loss = 1.9196511507034302\n",
      "Loss = 1.9059991836547852\n",
      "Loss = 1.7342913150787354\n",
      "Loss = 1.8073006868362427\n",
      "Loss = 1.7654341459274292\n",
      "Loss = 1.6976747512817383\n",
      "Loss = 1.6468032598495483\n",
      "Loss = 1.6886541843414307\n",
      "Loss = 1.5844513177871704\n",
      "Loss = 1.8827526569366455\n",
      "Loss = 1.7109957933425903\n",
      "Loss = 1.800611138343811\n",
      "Loss = 1.738107681274414\n",
      "Loss = 1.6308454275131226\n",
      "Loss = 1.953688383102417\n",
      "Loss = 1.782996654510498\n",
      "Loss = 1.7838282585144043\n",
      "Loss = 1.6831789016723633\n",
      "Loss = 1.690798044204712\n",
      "Loss = 1.69588041305542\n",
      "Loss = 1.7506924867630005\n",
      "Loss = 1.5873559713363647\n",
      "Loss = 1.6378707885742188\n",
      "Loss = 1.9525409936904907\n",
      "Loss = 1.679013967514038\n",
      "Loss = 1.9402499198913574\n",
      "Loss = 1.5825482606887817\n",
      "Loss = 1.839369297027588\n",
      "Loss = 1.6602262258529663\n",
      "Loss = 1.9495346546173096\n",
      "Loss = 1.8294639587402344\n",
      "Epoch 12/20, Loss: 1.7624\n",
      "Loss = 1.7348675727844238\n",
      "Loss = 1.8311446905136108\n",
      "Loss = 1.8013453483581543\n",
      "Loss = 1.8174850940704346\n",
      "Loss = 1.816793441772461\n",
      "Loss = 1.8673417568206787\n",
      "Loss = 1.7117650508880615\n",
      "Loss = 1.6606614589691162\n",
      "Loss = 1.63199782371521\n",
      "Loss = 1.732084035873413\n",
      "Loss = 1.7663774490356445\n",
      "Loss = 1.7271792888641357\n",
      "Loss = 1.7121230363845825\n",
      "Loss = 1.9220046997070312\n",
      "Loss = 1.682265043258667\n",
      "Loss = 1.8125630617141724\n",
      "Loss = 1.748498558998108\n",
      "Loss = 1.7130016088485718\n",
      "Loss = 1.8396899700164795\n",
      "Loss = 1.8696155548095703\n",
      "Loss = 1.6796278953552246\n",
      "Loss = 1.7089471817016602\n",
      "Loss = 1.6630196571350098\n",
      "Loss = 1.7585194110870361\n",
      "Loss = 1.660402774810791\n",
      "Loss = 1.8335545063018799\n",
      "Loss = 1.5618938207626343\n",
      "Loss = 1.6370048522949219\n",
      "Loss = 1.7582178115844727\n",
      "Loss = 1.7161544561386108\n",
      "Loss = 1.665203332901001\n",
      "Loss = 1.7427133321762085\n",
      "Loss = 2.249035596847534\n",
      "Loss = 1.6461669206619263\n",
      "Loss = 1.9615200757980347\n",
      "Loss = 1.7755061388015747\n",
      "Loss = 1.7737525701522827\n",
      "Loss = 1.796994924545288\n",
      "Loss = 1.8019285202026367\n",
      "Loss = 1.7556474208831787\n",
      "Loss = 1.731885552406311\n",
      "Loss = 1.7875443696975708\n",
      "Loss = 1.7491704225540161\n",
      "Loss = 1.7869514226913452\n",
      "Loss = 1.808525562286377\n",
      "Loss = 1.7829813957214355\n",
      "Loss = 1.7045644521713257\n",
      "Loss = 1.7310049533843994\n",
      "Loss = 1.7771453857421875\n",
      "Loss = 1.8282839059829712\n",
      "Loss = 1.8133128881454468\n",
      "Loss = 2.023735284805298\n",
      "Loss = 1.7848693132400513\n",
      "Loss = 1.7254810333251953\n",
      "Loss = 1.7767949104309082\n",
      "Loss = 1.5731712579727173\n",
      "Loss = 1.832929015159607\n",
      "Loss = 1.6640127897262573\n",
      "Loss = 1.7308144569396973\n",
      "Loss = 1.7759681940078735\n",
      "Loss = 1.7143148183822632\n",
      "Loss = 1.7035894393920898\n",
      "Loss = 1.8493616580963135\n",
      "Loss = 1.8319029808044434\n",
      "Loss = 1.789542555809021\n",
      "Loss = 1.4935474395751953\n",
      "Epoch 13/20, Loss: 1.7624\n",
      "Loss = 1.6654566526412964\n",
      "Loss = 1.6195248365402222\n",
      "Loss = 1.9091782569885254\n",
      "Loss = 1.8878848552703857\n",
      "Loss = 1.6406115293502808\n",
      "Loss = 1.7202296257019043\n",
      "Loss = 1.788936972618103\n",
      "Loss = 1.5577224493026733\n",
      "Loss = 1.6533944606781006\n",
      "Loss = 1.6247491836547852\n",
      "Loss = 1.5831342935562134\n",
      "Loss = 1.8429361581802368\n",
      "Loss = 1.6356407403945923\n",
      "Loss = 1.7447750568389893\n",
      "Loss = 1.9003970623016357\n",
      "Loss = 1.8546440601348877\n",
      "Loss = 1.7872484922409058\n",
      "Loss = 1.6646430492401123\n",
      "Loss = 1.7777388095855713\n",
      "Loss = 1.8228005170822144\n",
      "Loss = 1.756730079650879\n",
      "Loss = 1.7933472394943237\n",
      "Loss = 1.6254827976226807\n",
      "Loss = 1.6015737056732178\n",
      "Loss = 1.8130744695663452\n",
      "Loss = 1.702172875404358\n",
      "Loss = 1.8260211944580078\n",
      "Loss = 1.831562876701355\n",
      "Loss = 1.5978869199752808\n",
      "Loss = 1.7901496887207031\n",
      "Loss = 1.8512223958969116\n",
      "Loss = 1.7478814125061035\n",
      "Loss = 1.8113526105880737\n",
      "Loss = 1.8248876333236694\n",
      "Loss = 1.6998140811920166\n",
      "Loss = 1.7340078353881836\n",
      "Loss = 1.9166134595870972\n",
      "Loss = 1.837654948234558\n",
      "Loss = 1.7341543436050415\n",
      "Loss = 1.722156047821045\n",
      "Loss = 1.729549765586853\n",
      "Loss = 1.817158818244934\n",
      "Loss = 1.7995105981826782\n",
      "Loss = 1.7941014766693115\n",
      "Loss = 1.7534641027450562\n",
      "Loss = 1.7699546813964844\n",
      "Loss = 1.7943453788757324\n",
      "Loss = 1.6882036924362183\n",
      "Loss = 1.623833417892456\n",
      "Loss = 1.5799696445465088\n",
      "Loss = 1.9784663915634155\n",
      "Loss = 1.8384556770324707\n",
      "Loss = 1.7042776346206665\n",
      "Loss = 1.853487253189087\n",
      "Loss = 1.8661128282546997\n",
      "Loss = 1.7913572788238525\n",
      "Loss = 1.8345835208892822\n",
      "Loss = 1.9249277114868164\n",
      "Loss = 1.7112371921539307\n",
      "Loss = 1.756644368171692\n",
      "Loss = 1.8007001876831055\n",
      "Loss = 1.6595734357833862\n",
      "Loss = 1.8016561269760132\n",
      "Loss = 1.7706201076507568\n",
      "Loss = 1.8104724884033203\n",
      "Loss = 1.5739372968673706\n",
      "Epoch 14/20, Loss: 1.7565\n",
      "Loss = 1.7219772338867188\n",
      "Loss = 1.6154510974884033\n",
      "Loss = 2.0484557151794434\n",
      "Loss = 1.6435418128967285\n",
      "Loss = 1.7197339534759521\n",
      "Loss = 1.626802921295166\n",
      "Loss = 1.718784213066101\n",
      "Loss = 1.7189074754714966\n",
      "Loss = 1.6316512823104858\n",
      "Loss = 1.848053216934204\n",
      "Loss = 1.6203244924545288\n",
      "Loss = 1.7738385200500488\n",
      "Loss = 1.6689423322677612\n",
      "Loss = 1.8785203695297241\n",
      "Loss = 1.8792712688446045\n",
      "Loss = 1.6967763900756836\n",
      "Loss = 1.638098120689392\n",
      "Loss = 1.792083740234375\n",
      "Loss = 1.782631278038025\n",
      "Loss = 1.8642818927764893\n",
      "Loss = 1.8610482215881348\n",
      "Loss = 1.6890376806259155\n",
      "Loss = 1.7195026874542236\n",
      "Loss = 1.7953404188156128\n",
      "Loss = 1.5997810363769531\n",
      "Loss = 1.6081494092941284\n",
      "Loss = 1.6606968641281128\n",
      "Loss = 1.766344666481018\n",
      "Loss = 1.6383816003799438\n",
      "Loss = 1.512463927268982\n",
      "Loss = 1.7924755811691284\n",
      "Loss = 1.6393550634384155\n",
      "Loss = 2.051147699356079\n",
      "Loss = 1.9803681373596191\n",
      "Loss = 1.977583646774292\n",
      "Loss = 1.7531110048294067\n",
      "Loss = 1.8281207084655762\n",
      "Loss = 1.744840383529663\n",
      "Loss = 1.7608020305633545\n",
      "Loss = 1.685412883758545\n",
      "Loss = 1.834816813468933\n",
      "Loss = 1.7841683626174927\n",
      "Loss = 1.7495238780975342\n",
      "Loss = 1.7240651845932007\n",
      "Loss = 1.7787396907806396\n",
      "Loss = 1.7800159454345703\n",
      "Loss = 1.7699891328811646\n",
      "Loss = 1.7241661548614502\n",
      "Loss = 1.744020700454712\n",
      "Loss = 1.7608420848846436\n",
      "Loss = 1.8223416805267334\n",
      "Loss = 1.8040086030960083\n",
      "Loss = 1.689841389656067\n",
      "Loss = 1.7129474878311157\n",
      "Loss = 1.730341911315918\n",
      "Loss = 1.8928077220916748\n",
      "Loss = 1.872077226638794\n",
      "Loss = 1.7243307828903198\n",
      "Loss = 1.803253173828125\n",
      "Loss = 1.73984694480896\n",
      "Loss = 1.6383326053619385\n",
      "Loss = 1.7293294668197632\n",
      "Loss = 1.8296154737472534\n",
      "Loss = 1.9084874391555786\n",
      "Loss = 1.6904360055923462\n",
      "Loss = 1.7490049600601196\n",
      "Epoch 15/20, Loss: 1.7567\n",
      "Loss = 1.6269080638885498\n",
      "Loss = 1.6677485704421997\n",
      "Loss = 1.8438228368759155\n",
      "Loss = 1.7928775548934937\n",
      "Loss = 1.7486755847930908\n",
      "Loss = 1.9536139965057373\n",
      "Loss = 1.877079963684082\n",
      "Loss = 1.8414939641952515\n",
      "Loss = 1.5949755907058716\n",
      "Loss = 1.6900326013565063\n",
      "Loss = 1.6692875623703003\n",
      "Loss = 1.722469687461853\n",
      "Loss = 1.7275326251983643\n",
      "Loss = 1.7108244895935059\n",
      "Loss = 1.7504349946975708\n",
      "Loss = 1.795311689376831\n",
      "Loss = 1.8015953302383423\n",
      "Loss = 1.7638288736343384\n",
      "Loss = 1.7688045501708984\n",
      "Loss = 1.5792711973190308\n",
      "Loss = 2.022650718688965\n",
      "Loss = 1.610257625579834\n",
      "Loss = 1.7767759561538696\n",
      "Loss = 1.671415090560913\n",
      "Loss = 1.7421365976333618\n",
      "Loss = 1.6053259372711182\n",
      "Loss = 1.6811891794204712\n",
      "Loss = 1.7006703615188599\n",
      "Loss = 2.110968589782715\n",
      "Loss = 1.7569708824157715\n",
      "Loss = 1.7377111911773682\n",
      "Loss = 1.721674919128418\n",
      "Loss = 1.7948534488677979\n",
      "Loss = 1.6289349794387817\n",
      "Loss = 1.6120978593826294\n",
      "Loss = 1.8064920902252197\n",
      "Loss = 1.8291821479797363\n",
      "Loss = 1.6676428318023682\n",
      "Loss = 1.832762360572815\n",
      "Loss = 1.8476516008377075\n",
      "Loss = 1.752573013305664\n",
      "Loss = 1.693639874458313\n",
      "Loss = 1.645546793937683\n",
      "Loss = 1.7591530084609985\n",
      "Loss = 1.6571128368377686\n",
      "Loss = 1.7648802995681763\n",
      "Loss = 1.6321487426757812\n",
      "Loss = 1.814741849899292\n",
      "Loss = 1.5744861364364624\n",
      "Loss = 1.748414397239685\n",
      "Loss = 1.8248342275619507\n",
      "Loss = 1.738582730293274\n",
      "Loss = 1.6877822875976562\n",
      "Loss = 1.557735562324524\n",
      "Loss = 1.7264338731765747\n",
      "Loss = 1.872466802597046\n",
      "Loss = 1.9373736381530762\n",
      "Loss = 1.7495769262313843\n",
      "Loss = 1.7875261306762695\n",
      "Loss = 1.701210856437683\n",
      "Loss = 1.7437971830368042\n",
      "Loss = 1.701749563217163\n",
      "Loss = 1.868819236755371\n",
      "Loss = 1.816576600074768\n",
      "Loss = 1.726495623588562\n",
      "Loss = 1.7112340927124023\n",
      "Epoch 16/20, Loss: 1.7466\n",
      "Loss = 1.9098459482192993\n",
      "Loss = 1.8107948303222656\n",
      "Loss = 1.881162166595459\n",
      "Loss = 1.69420325756073\n",
      "Loss = 1.6606014966964722\n",
      "Loss = 1.647123098373413\n",
      "Loss = 1.6847753524780273\n",
      "Loss = 1.7146481275558472\n",
      "Loss = 1.5915192365646362\n",
      "Loss = 1.6458524465560913\n",
      "Loss = 1.7191969156265259\n",
      "Loss = 1.8621729612350464\n",
      "Loss = 2.0535194873809814\n",
      "Loss = 1.6264705657958984\n",
      "Loss = 1.510955810546875\n",
      "Loss = 1.781188726425171\n",
      "Loss = 1.55812668800354\n",
      "Loss = 1.9497337341308594\n",
      "Loss = 1.8601537942886353\n",
      "Loss = 1.8479297161102295\n",
      "Loss = 1.7344549894332886\n",
      "Loss = 1.7161216735839844\n",
      "Loss = 1.6670293807983398\n",
      "Loss = 1.756462812423706\n",
      "Loss = 1.781177043914795\n",
      "Loss = 1.761751413345337\n",
      "Loss = 1.7344154119491577\n",
      "Loss = 1.6186559200286865\n",
      "Loss = 1.564810037612915\n",
      "Loss = 1.6622014045715332\n",
      "Loss = 1.9274604320526123\n",
      "Loss = 1.5235776901245117\n",
      "Loss = 1.810418963432312\n",
      "Loss = 1.7100471258163452\n",
      "Loss = 1.8597173690795898\n",
      "Loss = 1.8843227624893188\n",
      "Loss = 1.7243316173553467\n",
      "Loss = 1.7279409170150757\n",
      "Loss = 1.6501421928405762\n",
      "Loss = 1.7108325958251953\n",
      "Loss = 1.757957100868225\n",
      "Loss = 1.581919550895691\n",
      "Loss = 1.693216323852539\n",
      "Loss = 1.6697514057159424\n",
      "Loss = 1.6459732055664062\n",
      "Loss = 1.850443959236145\n",
      "Loss = 2.00410532951355\n",
      "Loss = 1.5998188257217407\n",
      "Loss = 1.6883097887039185\n",
      "Loss = 1.9948019981384277\n",
      "Loss = 1.7141376733779907\n",
      "Loss = 1.740837574005127\n",
      "Loss = 1.7375216484069824\n",
      "Loss = 1.7226953506469727\n",
      "Loss = 1.8247452974319458\n",
      "Loss = 1.7292547225952148\n",
      "Loss = 1.752418875694275\n",
      "Loss = 1.972123384475708\n",
      "Loss = 1.7963968515396118\n",
      "Loss = 1.8187191486358643\n",
      "Loss = 1.7183892726898193\n",
      "Loss = 1.8031370639801025\n",
      "Loss = 1.7894244194030762\n",
      "Loss = 1.8375154733657837\n",
      "Loss = 1.7957019805908203\n",
      "Loss = 1.8621307611465454\n",
      "Epoch 17/20, Loss: 1.7521\n",
      "Loss = 1.7541322708129883\n",
      "Loss = 1.7392337322235107\n",
      "Loss = 1.776158332824707\n",
      "Loss = 1.753340482711792\n",
      "Loss = 1.7395447492599487\n",
      "Loss = 1.6799688339233398\n",
      "Loss = 1.668745994567871\n",
      "Loss = 1.7228920459747314\n",
      "Loss = 1.6657891273498535\n",
      "Loss = 1.7825433015823364\n",
      "Loss = 1.9521034955978394\n",
      "Loss = 1.8977822065353394\n",
      "Loss = 1.8055788278579712\n",
      "Loss = 1.7696152925491333\n",
      "Loss = 1.6723946332931519\n",
      "Loss = 1.6706433296203613\n",
      "Loss = 1.7393280267715454\n",
      "Loss = 1.7621769905090332\n",
      "Loss = 1.6902673244476318\n",
      "Loss = 1.9139323234558105\n",
      "Loss = 1.8008034229278564\n",
      "Loss = 1.7980340719223022\n",
      "Loss = 1.683804988861084\n",
      "Loss = 1.6314723491668701\n",
      "Loss = 1.7463650703430176\n",
      "Loss = 1.900766134262085\n",
      "Loss = 1.624300479888916\n",
      "Loss = 1.8187636137008667\n",
      "Loss = 1.8456584215164185\n",
      "Loss = 1.9133373498916626\n",
      "Loss = 1.7449448108673096\n",
      "Loss = 1.7956780195236206\n",
      "Loss = 1.722904920578003\n",
      "Loss = 1.5936216115951538\n",
      "Loss = 1.7242343425750732\n",
      "Loss = 1.8429460525512695\n",
      "Loss = 1.6174198389053345\n",
      "Loss = 1.7215443849563599\n",
      "Loss = 1.7495248317718506\n",
      "Loss = 1.7312194108963013\n",
      "Loss = 1.544009804725647\n",
      "Loss = 1.7112147808074951\n",
      "Loss = 1.7803808450698853\n",
      "Loss = 1.687613606452942\n",
      "Loss = 1.7089749574661255\n",
      "Loss = 1.526508092880249\n",
      "Loss = 1.8604509830474854\n",
      "Loss = 1.9517571926116943\n",
      "Loss = 1.57820463180542\n",
      "Loss = 1.7259502410888672\n",
      "Loss = 1.9261701107025146\n",
      "Loss = 1.665502667427063\n",
      "Loss = 1.7494475841522217\n",
      "Loss = 1.6490598917007446\n",
      "Loss = 1.7971642017364502\n",
      "Loss = 1.719435691833496\n",
      "Loss = 1.816820502281189\n",
      "Loss = 1.8249669075012207\n",
      "Loss = 1.754747986793518\n",
      "Loss = 1.758976697921753\n",
      "Loss = 1.7387388944625854\n",
      "Loss = 1.7152045965194702\n",
      "Loss = 1.7620165348052979\n",
      "Loss = 1.9116239547729492\n",
      "Loss = 1.7203084230422974\n",
      "Loss = 1.67514169216156\n",
      "Epoch 18/20, Loss: 1.7488\n",
      "Loss = 1.7301185131072998\n",
      "Loss = 1.7843843698501587\n",
      "Loss = 1.8315351009368896\n",
      "Loss = 1.709088683128357\n",
      "Loss = 1.6418006420135498\n",
      "Loss = 1.6909153461456299\n",
      "Loss = 1.696273684501648\n",
      "Loss = 1.5096962451934814\n",
      "Loss = 1.6002211570739746\n",
      "Loss = 1.613224744796753\n",
      "Loss = 1.5794973373413086\n",
      "Loss = 1.7627043724060059\n",
      "Loss = 1.455978274345398\n",
      "Loss = 1.6600005626678467\n",
      "Loss = 1.8162862062454224\n",
      "Loss = 2.0311567783355713\n",
      "Loss = 1.7714170217514038\n",
      "Loss = 1.6620628833770752\n",
      "Loss = 1.7104369401931763\n",
      "Loss = 1.7413111925125122\n",
      "Loss = 1.8210684061050415\n",
      "Loss = 1.7704355716705322\n",
      "Loss = 1.8111286163330078\n",
      "Loss = 1.7156991958618164\n",
      "Loss = 1.6904933452606201\n",
      "Loss = 1.7434242963790894\n",
      "Loss = 1.7603790760040283\n",
      "Loss = 1.6582598686218262\n",
      "Loss = 1.7727583646774292\n",
      "Loss = 1.8198765516281128\n",
      "Loss = 1.6750084161758423\n",
      "Loss = 1.6931935548782349\n",
      "Loss = 1.6741774082183838\n",
      "Loss = 1.8844804763793945\n",
      "Loss = 1.9021176099777222\n",
      "Loss = 1.8326373100280762\n",
      "Loss = 1.7812389135360718\n",
      "Loss = 1.8157156705856323\n",
      "Loss = 1.9316073656082153\n",
      "Loss = 1.967521071434021\n",
      "Loss = 1.8163371086120605\n",
      "Loss = 1.7529159784317017\n",
      "Loss = 1.8188523054122925\n",
      "Loss = 1.713034987449646\n",
      "Loss = 1.8691070079803467\n",
      "Loss = 1.771504521369934\n",
      "Loss = 1.8222129344940186\n",
      "Loss = 1.7189122438430786\n",
      "Loss = 1.7572064399719238\n",
      "Loss = 1.8972218036651611\n",
      "Loss = 1.7936726808547974\n",
      "Loss = 1.767488956451416\n",
      "Loss = 1.8918849229812622\n",
      "Loss = 1.7737265825271606\n",
      "Loss = 1.7676949501037598\n",
      "Loss = 1.6310681104660034\n",
      "Loss = 1.6926360130310059\n",
      "Loss = 1.9784950017929077\n",
      "Loss = 1.8622162342071533\n",
      "Loss = 1.9339232444763184\n",
      "Loss = 1.675071358680725\n",
      "Loss = 1.6688836812973022\n",
      "Loss = 1.7330925464630127\n",
      "Loss = 1.619357705116272\n",
      "Loss = 1.7326627969741821\n",
      "Loss = 1.8937753438949585\n",
      "Epoch 19/20, Loss: 1.7587\n",
      "Loss = 1.7838714122772217\n",
      "Loss = 1.8685120344161987\n",
      "Loss = 1.7424960136413574\n",
      "Loss = 1.718793511390686\n",
      "Loss = 1.814292311668396\n",
      "Loss = 1.7045106887817383\n",
      "Loss = 1.7466866970062256\n",
      "Loss = 1.7477165460586548\n",
      "Loss = 1.7838019132614136\n",
      "Loss = 1.815891981124878\n",
      "Loss = 1.8096786737442017\n",
      "Loss = 1.6650733947753906\n",
      "Loss = 1.825045108795166\n",
      "Loss = 1.7522956132888794\n",
      "Loss = 1.7007397413253784\n",
      "Loss = 1.8848118782043457\n",
      "Loss = 1.7011733055114746\n",
      "Loss = 1.8406009674072266\n",
      "Loss = 1.7448779344558716\n",
      "Loss = 1.6894773244857788\n",
      "Loss = 1.7981314659118652\n",
      "Loss = 1.6372408866882324\n",
      "Loss = 1.7247562408447266\n",
      "Loss = 1.7969211339950562\n",
      "Loss = 1.86781644821167\n",
      "Loss = 1.8412175178527832\n",
      "Loss = 1.6922191381454468\n",
      "Loss = 1.8582180738449097\n",
      "Loss = 1.8558226823806763\n",
      "Loss = 1.574065089225769\n",
      "Loss = 1.697121262550354\n",
      "Loss = 1.7825089693069458\n",
      "Loss = 1.815096378326416\n",
      "Loss = 1.7250574827194214\n",
      "Loss = 1.7079260349273682\n",
      "Loss = 1.6988179683685303\n",
      "Loss = 1.7654054164886475\n",
      "Loss = 1.7967721223831177\n",
      "Loss = 1.6359854936599731\n",
      "Loss = 1.7055118083953857\n",
      "Loss = 1.6935166120529175\n",
      "Loss = 1.590012788772583\n",
      "Loss = 1.7240413427352905\n",
      "Loss = 1.6710714101791382\n",
      "Loss = 1.776047706604004\n",
      "Loss = 1.6446495056152344\n",
      "Loss = 1.848323941230774\n",
      "Loss = 2.0628886222839355\n",
      "Loss = 1.7413549423217773\n",
      "Loss = 1.7152643203735352\n",
      "Loss = 1.7059375047683716\n",
      "Loss = 1.7507059574127197\n",
      "Loss = 1.6833335161209106\n",
      "Loss = 1.686600923538208\n",
      "Loss = 1.5831378698349\n",
      "Loss = 1.631612777709961\n",
      "Loss = 1.629696011543274\n",
      "Loss = 1.6623752117156982\n",
      "Loss = 1.648074984550476\n",
      "Loss = 1.748388648033142\n",
      "Loss = 1.9613678455352783\n",
      "Loss = 1.9244195222854614\n",
      "Loss = 1.930513858795166\n",
      "Loss = 1.6963658332824707\n",
      "Loss = 1.6681209802627563\n",
      "Loss = 1.544146180152893\n",
      "Epoch 20/20, Loss: 1.7460\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "# 開始訓練\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.permute(0, 2, 1)  # (batch_size, 8500, 2) -> (batch_size, 2, 8500)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 20.41%\n",
      "Accuracy: 23.81%\n"
     ]
    }
   ],
   "source": [
    "# 在驗證和測試集上評估\n",
    "evaluate_model(model, val_loader)\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_31924\\1578973231.py:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  torch.save(model, \"\\models\\CNN.pt\")\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_31924\\1578973231.py:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  torch.save(model, \"\\models\\CNN.pt\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory \\models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mCNN.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:651\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    648\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 651\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    652\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:525\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    524\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:496\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 496\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory \\models does not exist."
     ]
    }
   ],
   "source": [
    "torch.save(model, \"\\models\\CNN.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
